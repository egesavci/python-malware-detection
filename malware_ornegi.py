
# coding: utf-8


import pandas as pd
import numpy as np
import pickle
from sklearn import ensemble
from sklearn import model_selection, tree, linear_model
from sklearn.feature_selection import SelectFromModel
from sklearn.externals import joblib
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.svm import SVC
from sklearn.metrics import confusion_matrix #2x2 lik matris TP FP TN FN

data = pd.read_csv("data.csv",sep="|")
X = data.drop(["Name","md5","legitimate"],axis=1).values #md5 bi dosyanın butunluk kodu, drop ise bu 3 ünü at gerisini Xe at dedik
y = data['legitimate'].values #uygun ya da değil // normal veya zararlı dosya(0)

#print data.describe() 
#std yuksekse eleman arasında ucurumlar var ki bu ayırmayı kolaylaştırır. benzer seylerde std düşük olur which is bad.

feature_selector = ensemble.ExtraTreesClassifier().fit(X,y) #öznitelik seçici
model = SelectFromModel(feature_selector, prefit=True)
X_new = model.transform(X)
feature_size = X_new.shape[1]

X_train, X_test, y_train, y_test = model_selection.train_test_split(X_new,y,test_size=0.3)

features = []

for f in sorted(np.argsort(feature_selector.feature_importances_)[::-1][:feature_size]):
    features.append(data.columns[2+f])

models_params = {
    GaussianNB(): {},
    
    tree.DecisionTreeClassifier(): {
        'max_depth': list(range(1,20)),
        'max_features': list(range(1,feature_size + 1))
    
    },
}

model_results = {}



from sklearn.grid_search import GridSearchCV

for model, params in models_params.iteritems():
    grid = GridSearchCV(estimator=model, param_grid=params, n_jobs=4)
    grid.fit(X_train, y_train)
    
    test_score = grid.best_estimator_.score(X_test,y_test)
    model_results[grid.best_estimator_] = test_score  #uzun sürebilir


best_model = max(model_results, key = model_results.get)
print best_model
print
print model_results[best_model]



model = SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=None, degree=3, gamma=1e-05, kernel='rbf',
  max_iter=-1, probability=True, random_state=None, shrinking=True,
  tol=0.001, verbose=False) #max iter -> eğitebildiğin kadar eğit dedik -1 ile.

model.fit(X_train,y_train)
print "Eğitim bitti" 

'''eğitim uzun sürüyor cache size vb parametreler sürede etkili'''


''' onceden yarattıgın pickle dosyasını cagırmak için;

from sklearn.externals import joblib

model = joblib.load('yeni_model.pkl')

model.predict(X_test[150,:])
'''



from sklearn.externals import joblib
joblib.dump(best_model,'malware_model.pkl') #pickle a cevirme yerden tasarruf ve tekrar yuklendiginde kolaylik


import pickle

with open('yeni_model2.pkl', 'wb') as f:
    pickle.dump(best_model,f)





